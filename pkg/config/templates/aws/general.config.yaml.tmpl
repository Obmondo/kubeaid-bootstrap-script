forkURLs:
  # KubeAid repository URL (in HTTPs syntax).
  # Defaults to Obmondo's KubeAid repository.
  kubeaid: https://github.com/Obmondo/KubeAid

  # Your KubeAid config repository URL (in HTTPs syntax).
  kubeaidConfig: https://github.com/xxxxxxxxxx/kubeaid-config

# Kubernetes cluster and control-plane specific configurations.
cluster:

  # Kubernetes cluster name.
  name: kubeaid-demo-aws

  # Kubernetes version to use.
  # NOTE : Make sure that the AMI you're using, is targetted towards this Kubernetes version.
  k8sVersion: v1.31.0

  # Kubeaid version to use.
  kubeaidVersion: {{ .KubeAidVersion }}

  # Kubernetes API server specific configurations.
  # REFER : https://github.com/kubernetes-sigs/cluster-api/blob/main/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanes.yaml.
  #
  # NOTE : Generally, refer to the KubeadmControlPlane CRD instead of the corresponding GoLang
  #        source types linked below.
  #        There are some configuration options which appear in the corresponding GoLang source type,
  #        but not in the CRD. If you set those fields, then they get removed by the Kubeadm
  #        control-plane provider. This causes the capi-cluster ArgoCD App to always be in an
  #        OutOfSync state, resulting to the KubeAid Bootstrap Script not making any progress!
  # apiServer:
  #
  #   extraArgs: {}
  #
  #   # REFER : "sigs.k8s.io/cluster-api/bootstrap/kubeadm/api/v1beta1".HostPathMount
  #   #
  #   # NOTE : If you want a mount to be read-only, then set extraVolume.readOnly to true.
  #   #        Otherwise, omit setting that field. It gets removed by the Kubeadm control-plane
  #   #        provider component, which results to the capi-cluster ArgoCD App always being in
  #   #        OutOfSync state.
  #   extraVolumes: []
  #
  #   # REFER : "sigs.k8s.io/cluster-api/bootstrap/kubeadm/api/v1beta1".File
  #   files: []

  # Uncomment, if you just want audit-logging to work out of the box! KubeAid Bootstrap Script will
  # set necessary configuration options in cluster.apiServer.
  # enableAuditLogging: True

  # Any additional users you want to be setup for each Kubernetes node.
  # additionalUsers:
  #  - name: <username>
  #    sshPublicKey: xxxxxxxxxx

cloud:
  # AWS specific configurations.
  aws:
    region: us-east-2

    # AWS SSH Keypair name, which ClusterAPI components (Kubeadm bootstrap and control-plane
    # providers specifically) will use to SSH into the main cluster's master nodes.
    sshKeyName: kubeaid-demo

    # Use an existing VPC instead of Cluster API automatically spinning up a new one.
    # ClusterAPI will automatically create the remaining necessary infrastructure.
    # REFERENCE : https://cluster-api-aws.sigs.k8s.io/topics/failure-domains/control-planes#failure-domains-in-control-plane-nodes.
    # vpcID: xxxxxxxxxx

    # By default, a Bastion Host will be created.
    # bastionEnabled: True

    controlPlane:
      # loadBalancerScheme: internet-facing
      ami:
        id: ami-xxxxxxxxxxxxxxxxx
      instanceType: t4g.medium
      replicas: 3

    nodeGroups:
      - name: primary
        ami:
          id: ami-xxxxxxxxxxxxxxxxx
        instanceType: t4g.medium
        minSize: 1
        maxSize: 3
        rootVolumeSize: 35

        # AWS SSH Keypair name, which ClusterAPI components (Kubeadm bootstrap provider
        # specifically) will use to SSH into each node belonging to this node-group.
        sshKeyName: kubeaid-demo

        # A label should meet one of the following criterias to propagate to each of the nodes :
        #
        # (1) Has node-role.kubernetes.io as prefix.
        # (2) Belongs to node-restriction.kubernetes.io domain.
        # (3) Belongs to node.cluster.x-k8s.io domain.
        #
        # REFER : https://cluster-api.sigs.k8s.io/developer/architecture/controllers/metadata-propagation#machine
        labels:
          node.cluster.x-k8s.io/nodegroup: primary
          node-role.kubernetes.io/bootstrapper: ""

        # taints: []

    # Setup disaster recovery.
    # NOTE : Skips creating any of necessary S3 buckets, IAM Roles or Policies if they already
    # exist.
    disasterRecovery:
      # S3 bucket where Velero will backup Kubernetes objects.
      veleroBackupsS3BucketName: kubeaid-demo-kubernetes-objects

      # S3 Bucket where Sealed Secrets controller's private keys will be backed up.
      sealedSecretsBackupS3BucketName: kubeaid-demo-sealed-secrets

# monitoring:
#   kubePrometheusVersion: v0.14.0
